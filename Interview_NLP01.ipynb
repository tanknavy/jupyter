{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy,numpy as np\n",
    "np.random.seed(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output\n",
    "\n",
    "def sigmoid_output_to_derivative(output):\n",
    "    return output*(1-output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int2binary = {}\n",
    "binary_dim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "largest_number = pow(2,binary_dim);largest_number\n",
    "binary = np.unpackbits(\n",
    "    np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
    "for i in range(largest_number):\n",
    "    int2binary[i] = binary[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 1, 0, 1, 0], dtype=uint8), 256)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2binary[10],len(int2binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input variables\n",
    "alpha = 0.1\n",
    "input_dim = 2\n",
    "hidden_dim = 16\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize the neural network weights,否则不能启动\n",
    "synapse_0 = 2*np.random.random((input_dim,hidden_dim)) -1 # 输入，（0，1）变换到（-1，1）\n",
    "synapse_h = 2*np.random.random((hidden_dim,hidden_dim)) -1 # 隐层\n",
    "synapse_1 = 2*np.random.random((hidden_dim,output_dim)) -1 # 输出\n",
    "\n",
    "# initialize the weights derivative，\n",
    "synapse_0_update = np.zeros_like(synapse_0)\n",
    "synapse_h_update = np.zeros_like(synapse_h)\n",
    "synapse_1_update = np.zeros_like(synapse_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synapse_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " (2, 16))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synapse_0_update,synapse_0_update.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is: [0 0 1 0 0 0 0 0]\n",
      "b is: [0 0 1 0 1 0 1 1]\n",
      "guess is: [0 0 0 0 0 0 0 0]\n",
      "32 + 43 =0\n",
      "the error is: [3.77378019]\n",
      "--------------------------------------------\n",
      "a is: [0 0 0 0 1 0 1 1]\n",
      "b is: [0 0 0 0 0 1 1 1]\n",
      "guess is: [0 0 0 1 0 0 1 0]\n",
      "11 + 7 =18\n",
      "the error is: [1.00946714]\n",
      "--------------------------------------------\n",
      "a is: [0 1 0 1 1 1 1 1]\n",
      "b is: [0 0 0 0 0 1 1 1]\n",
      "guess is: [0 1 1 0 0 0 1 0]\n",
      "95 + 7 =98\n",
      "the error is: [1.69663157]\n",
      "--------------------------------------------\n",
      "a is: [0 1 1 0 0 0 1 0]\n",
      "b is: [0 0 1 0 0 0 1 1]\n",
      "guess is: [1 0 0 0 0 1 0 1]\n",
      "98 + 35 =133\n",
      "the error is: [1.01098954]\n",
      "--------------------------------------------\n",
      "a is: [0 0 0 1 0 1 0 0]\n",
      "b is: [0 1 1 1 0 1 0 1]\n",
      "guess is: [1 0 0 0 1 0 0 1]\n",
      "20 + 117 =137\n",
      "the error is: [2.12981935]\n",
      "--------------------------------------------\n",
      "a is: [0 0 0 1 1 0 1 0]\n",
      "b is: [0 1 0 0 0 0 1 0]\n",
      "guess is: [0 1 0 1 1 1 0 0]\n",
      "26 + 66 =92\n",
      "the error is: [0.27142224]\n",
      "--------------------------------------------\n",
      "a is: [0 1 0 1 1 0 1 1]\n",
      "b is: [0 1 1 0 1 1 0 0]\n",
      "guess is: [0 1 1 1 1 1 1 1]\n",
      "91 + 108 =127\n",
      "the error is: [3.5510877]\n",
      "--------------------------------------------\n",
      "a is: [0 1 0 1 1 1 0 0]\n",
      "b is: [0 0 0 1 1 1 0 1]\n",
      "guess is: [1 1 1 1 1 1 0 1]\n",
      "92 + 29 =253\n",
      "the error is: [2.77294418]\n",
      "--------------------------------------------\n",
      "a is: [0 0 1 0 0 1 0 0]\n",
      "b is: [0 1 0 1 0 0 0 0]\n",
      "guess is: [0 0 0 0 0 0 0 0]\n",
      "36 + 80 =0\n",
      "the error is: [2.97774773]\n",
      "--------------------------------------------\n",
      "a is: [0 0 1 0 0 0 1 1]\n",
      "b is: [0 0 1 1 1 0 1 1]\n",
      "guess is: [0 0 1 1 1 1 1 0]\n",
      "35 + 59 =62\n",
      "the error is: [2.91135924]\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# training logic\n",
    "for i in range(10000):\n",
    "    a_int = np.random.randint(largest_number/2) # 最大数不超过128\n",
    "    a     = int2binary[a_int]\n",
    "    b_int = np.random.randint(largest_number/2)\n",
    "    b     = int2binary[b_int]\n",
    "    \n",
    "    # true answer\n",
    "    c_int = a_int+b_int\n",
    "    c = int2binary[c_int]\n",
    "    \n",
    "    # where store the best guess(binary encoded)\n",
    "    d = np.zeros_like(c)\n",
    "    \n",
    "    overallError = 0\n",
    "    layer_2_deltas = list() # 输出错误对本次输入的导数\n",
    "    layer_1_values = list() # 第一层输出的值，同时会作为隐层加入到下一个值的输入中\n",
    "    layer_1_values.append(np.zeros(hidden_dim)) # 初始时隐层输入为0\n",
    "    \n",
    "    \n",
    "    # moving along the postions in the binary encoding from lower to higher\n",
    "    for position in range(binary_dim): # 循环一个序列的每个元素\n",
    "        \n",
    "        # 生成一个输入样本和正确输出，从低位到高位\n",
    "        # 为什么要二维？为了和二维得到权重正确的矩阵相乘\n",
    "        # 输入层\n",
    "        x = np.array([[a[binary_dim-position-1],b[binary_dim-position-1]]]) #1*2的二维数组,\n",
    "        y = np.array([[c[binary_dim-position-1]]]).T # 1×1 的二维数组，还要转置？\n",
    "        # 隐层 (input + prev_hidden)\n",
    "        layer_1 = sigmoid(np.dot(x,synapse_0) + np.dot(layer_1_values[-1],synapse_h)) # 上次隐层的输入也加入中\n",
    "        # 输出层\n",
    "        layer_2 = sigmoid(np.dot(layer_1,synapse_1))\n",
    "                      \n",
    "        # cost function\n",
    "        layer_2_error = y-layer_2 # 矩阵相减结果还是矩阵（1x1）, 假如用均方损失的话\n",
    "        layer_2_deltas.append(layer_2_error * sigmoid_output_to_derivative(layer_2)) # 对layer2的输入求导\n",
    "        overallError += np.abs(layer_2_error[0]) # 一维数组\n",
    "        \n",
    "        # decode 预计输出用于后续打印\n",
    "        d[binary_dim-position-1] = np.round(layer_2[0][0]) # 四舍五入取数\n",
    "        \n",
    "        # 储存本次隐藏输出用于下一个timestep\n",
    "        layer_1_values.append(copy.deepcopy(layer_1)) #注意使用深拷贝\n",
    "    \n",
    "    future_layer_1_delta = np.zeros(hidden_dim) # (1x16)最后一个隐层输出的导数，可以设置为0，因为对系统没有影响了\n",
    "    \n",
    "                      \n",
    "    for position in range(binary_dim): # 反向传播算法，从最后的误差BP\n",
    "        x = np.array([[a[position],b[position]]]) # 当前输入的x(1x2)\n",
    "        layer_1 = layer_1_values[-position-1] # layer_1的输出\n",
    "        prev_layer_1 = layer_1_values[-position-2] # 前一个layer_1的输出(16*16)，-9怎么办？\n",
    "        \n",
    "        # 逐层反向误差偏导\n",
    "        # error at output layer\n",
    "        layer_2_delta = layer_2_deltas[-position-1] # 当前输出的导数(1*1)\n",
    "        # error at hiddenlayer 前一层的导数\n",
    "        # 这层输出同时也是下个timestep的隐层输入，所以还要计算这次L1对下一次的影响，最tricy的地方\n",
    "        layer_1_delta = sigmoid_output_to_derivative(layer_1) * (np.dot(layer_2_delta, synapse_1.T) + \n",
    "                        np.dot(future_layer_1_delta, synapse_h)) \n",
    "        \n",
    "        #layer_1_delta = (future_layer_1_delta.dot(synapse_h.T) + \n",
    "        #                 layer_2_delta.dot(synapse_1.T)) * sigmoid_output_to_derivative(layer_1)  \n",
    "        \n",
    "        # 据此，根据求导链式法则，求三个weights（synapse_0，synapse_h，synapse_1）,参看上面正向传播的公式\n",
    "        # 这里每次都要累加，np.atleast_2d确保layer_1,pre_layer_1的输出必须是2维的\n",
    "        #synapse_1_update += np.dot(layer_1.T,layer_2_delta) # (16*1)\n",
    "        synapse_1_update += np.atleast_2d(layer_1).T.dot(layer_2_delta) # (16*1)，使用np.atleast2d？\n",
    "        # 隐层有些特殊，它的对当前输出的传播误差，还对下个timestep的输出传播误差，\n",
    "        #synapse_h_update += np.dot(layer_1_delta.T,prev_layer_1.reshape(1,16)) \n",
    "        synapse_h_update += np.atleast_2d(prev_layer_1).T.dot(layer_1_delta) # 使用np.atleast2d\n",
    "        synapse_0_update += np.dot(x.T,layer_1_delta) # \n",
    "        \n",
    "        future_layer_1_delta = layer_1_delta # ()\n",
    "    \n",
    "    # update weights,为什么要+，不是梯度的负方向吗？\n",
    "    synapse_0 += alpha * synapse_0_update  # 为什是+\n",
    "    synapse_h += alpha * synapse_h_update\n",
    "    synapse_1 += alpha * synapse_1_update\n",
    "    \n",
    "    # 前面梯度一直在+=，所以每个新样本时，权重需要重置为0\n",
    "    synapse_0_update *= 0\n",
    "    synapse_h_update *= 0\n",
    "    synapse_1_update *= 0\n",
    "    \n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print('a is:', a)\n",
    "        print('b is:', b)\n",
    "        print('guess is:',d)\n",
    "        \n",
    "        def bin2dec(bin):\n",
    "            dec = 0\n",
    "            length = len(bin)\n",
    "            for i in range(length):\n",
    "                dec += bin[i] * pow(2,(length-i-1))\n",
    "            return dec\n",
    "        \n",
    "        print('{} + {} ={}'.format(a_int, b_int, bin2dec(d)))\n",
    "        print('the error is:',overallError)\n",
    "        print('--------------------------------------------')\n",
    "                      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
