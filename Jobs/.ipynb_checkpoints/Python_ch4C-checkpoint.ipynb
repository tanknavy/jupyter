{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "__author__ = 'Alex Cheng'\n",
    "惩罚线性回归模型 --- K折\n",
    "Ridge回归通过对回归系数的平方和进行惩罚来避免过拟合(beta的平方和，L2)\n",
    "其他惩罚项：Lasso(L1), ElasticNet(a)\n",
    "Lasso的系数向量beta是稀疏的，即对不同的lambda值，许多稀疏等于0,\n",
    "相比之下Ridge的向量beta是密集的，大部分不等于0\n",
    "\n",
    "最小角度回归(LARS),可以理解为一种改进的前向逐步回归算法：在引入新属性时只是部分\n",
    "生成变量重要性排序是惩罚线性回归模型的一个重要特征\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets,linear_model\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_url3 = (\"http://archive.ics.uci.edu/ml/machine-learning-databases/\"\n",
    "\"wine-quality/winequality-red.csv\")\n",
    "df = pd.read_csv(target_url3,header=0,sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "xList  = np.array(df.iloc[:,:-1]) # 属性数组\n",
    "labels = [i for i in df.iloc[:,-1]] # 最后一列就是label\n",
    "\n",
    "# 正则化columns in x and labels\n",
    "nrows = len(xList)\n",
    "ncols = len(xList[0])\n",
    "\n",
    "# 计算means and variance\n",
    "xMeans = []\n",
    "xSD = []\n",
    "for i in range(ncols):\n",
    "    col = [xList[j][i] for j in range(nrows)]\n",
    "    mean = sum(col)/nrows\n",
    "    xMeans.append(mean)\n",
    "    colDiff = sum((col - mean) **2)\n",
    "    \n",
    "    colDiff2 = [(xList[j,i] - mean) for j in range(nrows) ]\n",
    "    sumSq = sum([colDiff2[i]  * colDiff2[i] for i in range(nrows)])\n",
    "    stdDev2 = sqrt(sumSq/nrows)\n",
    "    \n",
    "    stdDev = sqrt(colDiff/nrows)\n",
    "    xSD.append(stdDev)\n",
    "#print(xMeans,'\\n',xSD)\n",
    "print(stdDev == stdDev2) # broadcast广播变量的方式，发现结果一样\n",
    "\n",
    "\n",
    "# 正则化xList\n",
    "xNorm = []\n",
    "for i in range(nrows):\n",
    "    #rowNorm = ([xList[i] - xMeans]) / xSD  #列表不支持\n",
    "    rowNorm = [(xList[i,j] - xMeans[j]) / xSD[j] for j in range(ncols)]\n",
    "    xNorm.append(rowNorm)\n",
    "\n",
    "# 正则化 labels\n",
    "meanLable = sum(labels)/ nrows\n",
    "sdLabel = sqrt(sum([ (labels[i] - meanLable) * (labels[i] - meanLable) for i in range(nrows)]) / nrows)\n",
    "labelNorm = [ (labels[i] - meanLable) / sdLabel for i in range(nrows) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 从数百个LARS生成结果中选择最佳模型\n",
    "# 利用10折交叉验证来确定最佳系数集合\n",
    "\n",
    "#xList  = np.array(df.iloc[:,:-1]) # 属性数组\n",
    "#labels = [i for i in df.iloc[:,-1]] # 最后一列就是label\n",
    "xNorm,labelNorm # 正则化以后的x,y\n",
    "nxval = 10\n",
    "steps = 350\n",
    "stepSize = 0.004\n",
    "\n",
    "errors = []\n",
    "for i in range(steps):\n",
    "    b = []\n",
    "    errors.append(b)\n",
    "\n",
    "'''\n",
    "for ixval in range(nxval):\n",
    "    # Define test and traing index sets\n",
    "    idxTest =  [i for i in range(nrows) if i % nxval == ixval]\n",
    "    idxTrain = [i for i in range(nrows) if i % nxval != ixval]\n",
    "    pass\n",
    "idxTest =  [i for i in range(nrows) if i % nxval ==0]\n",
    "idxTrain = [i for i in range(nrows) if i % nxval !=0]\n",
    "\n",
    "# 定义测试和训练的属性和列表\n",
    "xTrain = [xNorm[r] for r in idxTrain]\n",
    "xTest  = [xNorm[r] for r in idxTest]\n",
    "yTrain = [labelNorm[r] for r in idxTrain]\n",
    "yTest  = [labelNorm[r] for r in idxTest]\n",
    "\n",
    "# 训练LARS回归\n",
    "nrowsTrain = len(idxTrain)\n",
    "nrowsTest  = len(idxTest)\n",
    "'''\n",
    "\n",
    "# 初始化 coefficients beta向量\n",
    "beta = [0.0] * ncols\n",
    "\n",
    "# 初始化 matrix of beta at each step\n",
    "betaMat = []\n",
    "betaMat.append(list(beta))\n",
    "\n",
    "\n",
    "for step in range(steps):\n",
    "    \n",
    "    ##### 10 折交叉验证, 训练接和测试集\n",
    "    k_fold_Error = [] # 10次的均值\n",
    "    \n",
    "    for ixval in range(nxval):\n",
    "    # Define test and traing index sets\n",
    "        idxTest =  [i for i in range(nrows) if i % nxval == ixval]\n",
    "        idxTrain = [i for i in range(nrows) if i % nxval != ixval]\n",
    "\n",
    "    #idxTest =  [i for i in range(nrows) if i % nxval ==0]\n",
    "    #idxTrain = [i for i in range(nrows) if i % nxval !=0]\n",
    "\n",
    "    # 定义测试和训练的属性和列表\n",
    "        xTrain = [xNorm[r] for r in idxTrain]\n",
    "        xTest  = [xNorm[r] for r in idxTest]\n",
    "        yTrain = [labelNorm[r] for r in idxTrain]\n",
    "        yTest  = [labelNorm[r] for r in idxTest]\n",
    "        nrowsTrain = len(idxTrain)\n",
    "        nrowsTest  = len(idxTest)\n",
    "        #print(len(xTrain),len(xTrain[0]),len(xTest),len(xTest[0]))\n",
    "        #print(xTrain)\n",
    "        \n",
    "    ###### 10折交叉验证，取10次平均值\n",
    "    \n",
    "        residuals = [0.0] * nrowsTrain # 全体记录数？?\n",
    "        for j in range(nrowsTrain): # 计算训练集的预测的残差\n",
    "            labelsHat = sum([xTrain[j][k] * beta[k] for k in range(ncols)])\n",
    "            residuals[j] = yTrain[j] - labelsHat\n",
    "    \n",
    "        # 计算每个列（属性）和残差的相关性\n",
    "        corr = [0.0] * ncols\n",
    "        for j in range(ncols):\n",
    "            corr[j] = sum([xTrain[k][j] * residuals[k] for k \\\n",
    "                       in range(nrowsTrain)]) / nrowsTrain\n",
    "    \n",
    "        iStart = 0\n",
    "        corrStart = corr[0]\n",
    "        for j in range(1,ncols): #找绝对值最大的系数\n",
    "            if abs(corrStart) < corr[j]:\n",
    "                iStart = j; corrStart = corr[j]\n",
    "            \n",
    "        beta[iStart] += stepSize * corrStart / abs(corrStart) # 对应beta值增加\n",
    "        betaMat.append(list(beta)) # 这个步骤的beta系数\n",
    "    \n",
    "        # 使用最新的beta系数预测测试接的错误\n",
    "        temp = []\n",
    "        for j in range(nrowsTest):\n",
    "            labelsHat = sum([xTest[j][k] * beta[k] for k in range(ncols)])\n",
    "            err = yTest[j] - labelsHat\n",
    "            temp.append(err)\n",
    "        #print(len(temp),type(temp))\n",
    "        #print(mean(temp)) # cannot mean?\n",
    "        errors[step].append(sum(temp)/len(temp))\n",
    "        \n",
    "            #errors[step].append(err)\n",
    "    #errors[step].append(err)\n",
    "\n",
    "     \n",
    "\n",
    "cvCurve = []\n",
    "print(len(errors),len(errors[0])) # 350 * \n",
    "for err in errors:\n",
    "    mse = sum([x*x for x in err]) / len(err)\n",
    "    cvCurve.append(mse)\n",
    "\n",
    "minMse = min(cvCurve)\n",
    "minPt = [i for i in range(len(cvCurve)) if cvCurve[i] == minMse] # 最小错误的step\n",
    "\n",
    "xaxis = range(len(cvCurve))\n",
    "plt.plot(xaxis,cvCurve)\n",
    "plt.xlabel('Steps Taken')\n",
    "plt.ylabel('Mean Square Values')\n",
    "plt.show()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
