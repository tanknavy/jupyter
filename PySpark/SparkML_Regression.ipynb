{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSpark的MLlib库提供了两大回归模型：线性模型和决策树模型\\n线性回归模型本质上和对应的线性分类模型一样，唯一的区别是线性回归使用的损失函数、\\n相关连接函数和决策函数不同。MLlib提供了标准的最小二乘回归模型\\n决策树同样可以通过改变不纯度的度量方法用于回归分析。\\n线性回归在应用L2正则化时通常称为岭回归（ridge regression），应用L1正则化是称为LASSO（Least Absolute Shrinkage and Selection Operator）。\\n决策树在用于回归时也要使用对应的不纯度度量方法。这里的不纯度度量方法是方差，和最小二乘回归模型定义方差损失的方式一样\\nhttp://archive.ics.uci.edu/ml/datasets.html\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Spark的MLlib库提供了两大回归模型：线性模型和决策树模型\n",
    "线性回归模型本质上和对应的线性分类模型一样，唯一的区别是线性回归使用的损失函数、\n",
    "相关连接函数和决策函数不同。MLlib提供了标准的最小二乘回归模型\n",
    "决策树同样可以通过改变不纯度的度量方法用于回归分析。\n",
    "线性回归在应用L2正则化时通常称为岭回归（ridge regression），应用L1正则化是称为LASSO（Least Absolute Shrinkage and Selection Operator）。\n",
    "决策树在用于回归时也要使用对应的不纯度度量方法。这里的不纯度度量方法是方差，和最小二乘回归模型定义方差损失的方式一样\n",
    "http://archive.ics.uci.edu/ml/datasets.html\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', '2011-01-01', '1', '0', '1', '0', '0', '6', '0', '1', '0.24', '0.2879', '0.81', '0', '3', '13', '16'], ['2', '2011-01-01', '1', '0', '1', '1', '0', '6', '0', '1', '0.22', '0.2727', '0.8', '0', '8', '32', '40'], ['3', '2011-01-01', '1', '0', '1', '2', '0', '6', '0', '1', '0.22', '0.2727', '0.8', '0', '5', '27', '32'], ['4', '2011-01-01', '1', '0', '1', '3', '0', '6', '0', '1', '0.24', '0.2879', '0.75', '0', '3', '10', '13'], ['5', '2011-01-01', '1', '0', '1', '4', '0', '6', '0', '1', '0.24', '0.2879', '0.75', '0', '0', '1', '1']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17379"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SparkContext(\"local[2]\",\"Spark ML Regression\")\n",
    "raw_data = sc.textFile(\"C:/input/spark/Bike-Sharing-Dataset/hour_noheader.csv\")\n",
    "num_data = raw_data.count()\n",
    "records = raw_data.map(lambda x:x.split(\",\"))\n",
    "print(records.take(5))\n",
    "num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
