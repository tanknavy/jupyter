{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"PySpark_DataFrame\").master(\"local[2]\").\\\n",
    "config(\"spark.sql.warehouse.dir\",\"file:///E:/input/spark/warehouse\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.ml.feature import VectorIndexer\n",
    "data = spark.read.format(\"libsvm\").load(\"file:///E://download/sample_libsvm_data.txt\") #692个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00045709826063783577,-0.00010363361374784932,-4.571905403906762e-05,0.0002251034584972664,0.0003143239168184688,9.792428586344767e-05,-0.0004165142434161362,-0.00023105320447086821,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0004077201876289535,0.00013698109070538062,0.0002017085782767603,-6.765269896686942e-05,-3.9761167571599894e-05,5.596731505368527e-05,1.9323015084544902e-05,1.721772271095574e-05,3.759921861471019e-05,1.797672090293095e-05,-5.924433912974708e-05,-1.0288313791153476e-05,2.5309658336315612e-05,0.00010485623019094176,-0.0003104591025548359,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00042263677985928376,0.00014380172592722639,0.00011199067621822119,3.057349313743097e-05,-4.8353392518757084e-05,-1.4593435515883095e-05,1.1570218325333318e-05,3.382024051263878e-07,-2.779496380135309e-05,-6.512628644376464e-05,-4.704607655456379e-05,-9.304465753145315e-06,-1.3994780458691694e-05,1.767948469610598e-05,6.567729680016298e-05,-2.2640710531640862e-05,-0.00012413478290732212,0.00016367402707224914,0.0009937351643671802,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00019803551970549202,4.5537669566991805e-05,-7.230031919443886e-05,-8.499318946336013e-05,-1.8780573833022433e-05,-9.82142088120074e-06,-2.5005364480327872e-05,1.8515439572269607e-05,-3.449462491298251e-05,5.671937066796236e-06,1.2740515169752613e-05,1.1900505007502233e-05,-6.7857809516732255e-06,9.246111329648309e-06,2.7310771131573538e-05,-5.355203019494996e-06,-1.4252885205033697e-05,5.5649169204562994e-05,9.52896732954876e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0004243314290605199,-8.040229992222201e-05,-5.602206706477069e-05,-3.745355984735908e-05,1.599173955166848e-05,-3.44373233422433e-05,-2.716223257524507e-05,-1.8237056424448435e-05,-8.986230770882904e-06,3.109911909438136e-05,2.3962377893638574e-05,-2.3293886650169635e-05,-2.526031632599472e-05,1.2801216005145323e-06,-2.0113828480078268e-05,4.189271187772734e-05,7.989973272524397e-05,4.0609689688446765e-05,5.5649169204563076e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0006852170959583142,-0.0001548443743016212,-6.992112515116726e-05,-3.4352585136701535e-05,4.2345684363042055e-05,-4.581354260561928e-06,-4.4269647158550096e-05,-1.9086961167528147e-05,5.194108842505429e-06,3.1675095857509113e-06,-7.682006288066717e-06,-4.6928080170676306e-05,-2.1899176796157024e-05,-4.653648497155397e-05,-6.97641790192102e-06,-3.0677459528092964e-05,1.2279421687919606e-05,3.5514041931915154e-05,-0.00016202054016135103,3.5521669588945726e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00011006820661947843,-6.73099716292972e-05,-7.079983092694133e-05,2.5374955082149948e-05,3.745562000740592e-05,-2.1276579658860277e-05,-5.423606801240788e-05,-1.1013592231006385e-05,1.0136400315358186e-06,2.2030501478675407e-06,1.0648596387306527e-05,-2.4017578235831515e-05,-2.7155156999078147e-06,-1.6921194938339477e-05,-4.238430832285925e-05,-8.171673517046196e-05,-6.525827478770118e-05,3.526416064345127e-05,-3.1935799162518595e-06,-0.00012710055480943274,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0001641331304609356,-1.723205462393444e-05,-1.7241154480942015e-05,6.672917811417632e-06,9.400298811721892e-06,-4.266156672312465e-05,-2.155394771800788e-06,3.5495218056798805e-05,9.408148992061366e-06,7.008826465099254e-05,4.580254252141825e-05,-2.439656493667957e-06,4.578284332927888e-06,-1.1906371256475783e-06,-2.715580927828017e-05,-5.937671288596795e-05,-7.481082956304739e-05,-2.195174230873127e-05,-6.222402698649703e-05,-9.588122449403159e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00011554998346040713,-2.6723053237033046e-05,-1.3836804715379054e-05,1.854327714449677e-05,-6.256902778223062e-06,-6.28422642448522e-07,-1.128239672975197e-06,2.9557483366518773e-06,3.0164021717918464e-05,4.357684727188754e-05,3.322056964843603e-05,-6.648040015511984e-06,2.4685483678068553e-05,3.401892374942944e-05,-4.816046685264621e-05,-4.1406815833635826e-05,-3.497747571389217e-05,-2.7636657236014734e-05,-5.101572176163239e-05,-9.498818316805492e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5.807282691184824e-05,-3.500378651111106e-05,2.5841556642752717e-05,2.7836131375499783e-05,1.7144470375956237e-05,-3.0044167611299723e-05,1.7591208103523635e-05,5.87075059426394e-06,-2.1203594019067078e-06,6.813114426692359e-05,6.682554130190401e-05,3.0467542768043402e-05,6.759903281784257e-05,-5.1351637510700354e-05,-8.515427449529256e-05,-5.5936287336595985e-05,-5.926140903882853e-05,2.880909432295701e-07,-4.560355625582136e-05,-9.946809330712822e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-9.47162760056928e-05,6.767438134395925e-06,1.7778621275314334e-05,-3.977288358519409e-05,-3.857838474278442e-05,-1.8895242202738518e-05,2.1211290653708144e-05,1.6947436175418367e-05,3.216966954291078e-05,0.00010135030184632723,7.841206014587837e-05,3.0774522215145496e-05,5.65149892448381e-06,-0.00012229919610207618,-8.097496925721297e-05,-5.904009658905928e-05,-5.534715610630104e-05,-1.9376829394361325e-05,-2.5486331682301778e-05,-9.020706785812655e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0020178406436267764,-0.0001270522634823492,-1.8518970322727466e-05,-1.5361726747921968e-05,-4.627433682146897e-05,-8.636540391291495e-06,-3.3001427325507355e-05,3.5930712251456866e-05,-1.0065499751325698e-05,7.232346771366358e-05,0.00011360209266721639,8.796954999300417e-05,-6.625791790487239e-06,1.1341418142145266e-05,-9.964509974918286e-05,-6.604249282355492e-05,-6.724525112318205e-05,-8.29633308048144e-05,4.631745414045937e-06,-1.0164847015303183e-05,-9.030287898240875e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0004974070309977658,-9.721746646214605e-05,-2.4214256531416568e-05,-1.2045499439708453e-05,-2.81672341804818e-05,-3.7239058248706016e-05,-5.791286781933357e-05,-8.531497602319429e-05,-1.846224719531779e-05,0.00010383266030515585,0.00012251983571584396,4.972990107905494e-05,2.6158790972518497e-05,0.00010652457169024934,-0.00010682237745307346,-5.3128972955486974e-05,-8.084358143507179e-05,-6.719010566461046e-05,-1.3891845284618355e-05,-3.1100694442816996e-05,-8.591363702837448e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0015427088631473256,-6.808324605308395e-05,-3.904120220751085e-05,-2.0415562606859483e-05,-5.5432208256846535e-05,-3.270776457350521e-05,-5.5056198477238445e-05,1.6927367708248103e-05,1.3475948574580369e-05,8.486617104970768e-05,0.00010636525438066482,1.9590663972708896e-06,-5.4892350040190866e-05,1.1956554443275566e-05,-7.727919118768597e-05,-7.359543995481631e-05,-7.070092505590736e-05,-7.134861108797373e-05,-7.230409234591232e-05,2.771727676953334e-06,-2.8584500326769855e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.000175042647569293,-6.369524953144926e-05,-3.9504718387354574e-05,-2.0873496226871414e-05,-5.771054795184852e-05,-3.378299910100335e-05,-8.50399595634639e-05,-2.0514761419658583e-05,-6.80901876825419e-06,8.253757337710769e-05,7.467916611434839e-05,1.131343955339566e-05,1.4935753979558059e-05,-8.811895329892938e-06,-2.2986215362678005e-05,-5.587602437344714e-05,-0.00011664447412916969,-6.184616446339129e-05,-1.2209878792229681e-05,2.8212289619684084e-05,-1.1328698795557344e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-7.072846063718095e-05,-3.476402978917993e-05,-6.319956559060667e-05,-2.497819057951936e-05,-3.368659180306521e-05,2.1741077395245236e-05,-1.9471545353138303e-05,-3.3272221604973686e-05,2.802103869919121e-05,0.00011230730330734324,6.266331984198949e-05,1.8961340641932424e-05,2.299896915692193e-05,-3.251251579154901e-05,-8.308370499223209e-05,-5.637954693389592e-05,-7.510545835393351e-05,3.4724309503763894e-05,3.30471283517636e-06,-2.8853620547575225e-05,-5.100197043215011e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-6.670898345853527e-05,-1.1363947263127144e-05,-3.6848838290213094e-05,-5.4511189671311e-05,-6.346550436091404e-05,1.3779732647228409e-05,5.827284541211761e-05,1.9545619794184983e-05,5.472155091333058e-05,9.116478269515086e-05,5.183578346925354e-05,2.146862776715006e-05,-5.287584542026356e-05,-4.964283450418767e-05,-6.246356725809684e-07,1.2779374038739898e-05,2.0262824610126943e-05,3.974346045854943e-05,7.663720915667323e-06,-4.992504125498715e-05,-4.398726984969471e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00010313437756855126,-2.0405602413311236e-05,-7.573036751855109e-06,-1.443183512360917e-05,-4.99193416554779e-05,-2.3367790214715957e-05,4.248209707750538e-05,3.038631666008723e-05,-2.8774371526205442e-06,1.7299095603967842e-05,4.397417825432117e-05,2.5634675120132262e-05,-8.872410534574737e-06,-1.6034745810792233e-05,6.083707294497904e-05,1.669666068508685e-05,1.5928022170899747e-05,1.5700657009050885e-05,-2.9440163567599267e-05,-9.39862648325585e-06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00022814889293547237,1.591418774377358e-05,0.00010475666496714149,6.082960202778718e-05,1.6780343982218555e-05,-3.822318587494952e-05,-1.199175597678177e-05,1.6615527847101056e-05,-1.0361337018546391e-05,2.1651854851150394e-05,2.9151769888838048e-06,1.3096654734641452e-05,-9.040276040184168e-06,2.9492163440625483e-05,-8.716051271231646e-06,-2.8347749359385685e-05,-1.907100278501871e-05,-3.253059704349288e-05,-7.593796515612352e-05,2.4547561924625003e-05,0.0,0.0,-0.0001664048552677082,0.0,0.0,0.0,0.0,0.0,-0.00026862692232725125,-2.446799735317731e-05,0.00021497171506029456,8.06491836987514e-05,7.606312160443477e-05,2.2260096391087763e-06,-2.6797681514822462e-05,-7.62940433547797e-06,-1.0698511322769305e-05,-2.7537548260656974e-05,-3.507377072039328e-05,1.5900028515897746e-05,1.496464759047676e-05,-4.718925628495745e-06,2.8554122106353465e-05,-6.376983925106436e-06,-4.574032374675074e-05,-5.369495281195184e-05,3.415739300446205e-06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00020066107450951096,7.537649100895693e-05,5.7301516359555136e-05,3.5370254212206104e-05,3.460880092170677e-05,6.236576842716182e-06,-3.1088631861704646e-05,-3.3455402351386885e-05,-5.5631894245297626e-05,-3.999101541012916e-05,-4.976129323201917e-05,-4.3226684257249585e-05,-1.819812218265197e-05,3.092585699035811e-05,-6.635324991486168e-07,-4.849761417554867e-06,0.00011240862626990848,-0.0003573393512045905,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00019079181551545415,2.3985537067018653e-05,5.071357930289486e-05,6.271710831533292e-05,-7.806820319416418e-06,-1.5080686789416915e-05,-5.6488209015990014e-05,-6.429514083876577e-05,-6.337237858090842e-06,1.817212345314005e-05,-7.751531876686431e-05,-4.5756151832054084e-05,3.0655112628235893e-06,-2.0399702355461343e-05]\n",
      "Intercept: 0.6139552540513642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Coefficient Standard Errors: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "\n",
      " T Values: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "\n",
      " Dispersion: -0.00036308666432333954\n",
      "\n",
      " Null Deviance: 24.50999999999997\n",
      "\n",
      " Residual Degree Of Freedom Null: 99\n",
      "\n",
      " Deviance: 0.21531039194374035\n",
      "\n",
      " Residual Degree Of Freedom: -593\n",
      "\n",
      " AIC: 1057.7032271916974\n",
      "\n",
      " Deviance Residuals: \n",
      "+--------------------+\n",
      "|   devianceResiduals|\n",
      "+--------------------+\n",
      "|-0.04489581502374462|\n",
      "|0.010287260575441826|\n",
      "|-0.02861493991522...|\n",
      "| 0.06442964489573966|\n",
      "|0.007493190261459337|\n",
      "|-0.07783803568944425|\n",
      "|0.009249931839144132|\n",
      "| 0.06668312531069676|\n",
      "|-0.08645681324247279|\n",
      "|-0.01224597666755789|\n",
      "|0.001166573732491516|\n",
      "| 0.01765209729353323|\n",
      "|  0.0199905433514197|\n",
      "| 0.03588518195566892|\n",
      "|-0.00999139248883607|\n",
      "| 0.01944938727657186|\n",
      "|0.010817641622237972|\n",
      "| 0.10290220859513355|\n",
      "|0.021070016734725194|\n",
      "|  7.6253426693762E-4|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "\n",
    "# Load training data\n",
    "dataset = spark.read.format(\"libsvm\").load(\"file:///E://download/sample_libsvm_data.txt\")\n",
    "\n",
    "glr = GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\", maxIter=10, regParam=0.3)\n",
    "\n",
    "# Fit the model\n",
    "model = glr.fit(dataset)\n",
    "\n",
    "# Print the coefficients and intercept for generalized linear regression model\n",
    "print(\"Coefficients: \" + str(model.coefficients))\n",
    "print(\"Intercept: \" + str(model.intercept))\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "summary = model.summary\n",
    "print(\"\\n Coefficient Standard Errors: \" + str(summary.coefficientStandardErrors))\n",
    "print(\"\\n T Values: \" + str(summary.tValues))\n",
    "#print(\"P Values: \" + str(summary.pValues))\n",
    "print(\"\\n Dispersion: \" + str(summary.dispersion))\n",
    "print(\"\\n Null Deviance: \" + str(summary.nullDeviance))\n",
    "print(\"\\n Residual Degree Of Freedom Null: \" + str(summary.residualDegreeOfFreedomNull))\n",
    "print(\"\\n Deviance: \" + str(summary.deviance))\n",
    "print(\"\\n Residual Degree Of Freedom: \" + str(summary.residualDegreeOfFreedom))\n",
    "print(\"\\n AIC: \" + str(summary.aic))\n",
    "print(\"\\n Deviance Residuals: \")\n",
    "summary.residuals().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Load training data\n",
    "dataset = spark.read.format(\"libsvm\").load(\"file:///E://download/sample_libsvm_data.txt\")\n",
    "\n",
    "#glr = GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\", maxIter=10, regParam=0.3)\n",
    "lr = LinearRegression(maxIter=10)\n",
    "\n",
    "#%debug\n",
    "# Fit the model\n",
    "model = lr.fit(dataset)\n",
    "\n",
    "# Print the coefficients and intercept for generalized linear regression model\n",
    "print(\"Coefficients: \" + str(model.coefficients))\n",
    "print(\"Intercept: \" + str(model.intercept))\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "summary = model.summary\n",
    "#print(\"Coefficient Standard Errors: \" + str(summary.coefficientStandardErrors))\n",
    "#print(\"T Values: \" + str(summary.tValues))\n",
    "#print(\"P Values: \" + str(summary.pValues))\n",
    "#print(\"Dispersion: \" + str(summary.dispersion))\n",
    "#print(\"Null Deviance: \" + str(summary.nullDeviance))\n",
    "#print(\"Residual Degree Of Freedom Null: \" + str(summary.residualDegreeOfFreedomNull))\n",
    "#print(\"Deviance: \" + str(summary.deviance))\n",
    "#print(\"Residual Degree Of Freedom: \" + str(summary.residualDegreeOfFreedom))\n",
    "#print(\"AIC: \" + str(summary.aic))\n",
    "#print(\"Deviance Residuals: \")\n",
    "#summary.residuals().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
