{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"PySpark_DataFrame\").master(\"local[2]\").\\\n",
    "config(\"spark.sql.warehouse.dir\",\"file:///E:/input/spark/warehouse\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.ml.feature import VectorIndexer\n",
    "data = spark.read.format(\"libsvm\").load(\"file:///E://download/sample_libsvm_data.txt\") #692个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: (692,[244,263,272,300,301,328,350,351,378,379,405,406,407,428,433,434,455,456,461,462,483,484,489,490,496,511,512,517,539,540,568],[-7.353983524188197e-05,-9.102738505589466e-05,-0.00019467430546904298,-0.00020300642473486668,-3.1476183314863995e-05,-6.842977602660743e-05,1.5883626898239883e-05,1.4023497091372047e-05,0.00035432047524968605,0.00011443272898171087,0.00010016712383666666,0.0006014109303795481,0.0002840248179122762,-0.00011541084736508837,0.000385996886312906,0.000635019557424107,-0.00011506412384575676,-0.00015271865864986808,0.0002804933808994214,0.0006070117471191634,-0.0002008459663247437,-0.0001421075579290126,0.0002739010341160883,0.00027730456244968115,-9.838027027269332e-05,-0.0003808522443517704,-0.00025315198008555033,0.00027747714770754307,-0.0002443619763919199,-0.0015394744687597765,-0.00023073328411331293])\n",
      "Intercept: 0.22456315961250325\n",
      "Multinomial coefficients: 2 X 692 CSRMatrix\n",
      "(0,244) 0.0\n",
      "(0,263) 0.0001\n",
      "(0,272) 0.0001\n",
      "(0,300) 0.0001\n",
      "(0,350) -0.0\n",
      "(0,351) -0.0\n",
      "(0,378) -0.0\n",
      "(0,379) -0.0\n",
      "(0,405) -0.0\n",
      "(0,406) -0.0006\n",
      "(0,407) -0.0001\n",
      "(0,428) 0.0001\n",
      "(0,433) -0.0\n",
      "(0,434) -0.0007\n",
      "(0,455) 0.0001\n",
      "(0,456) 0.0001\n",
      "..\n",
      "..\n",
      "Multinomial intercepts: [-0.12065879445860686,0.12065879445860686]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator,BinaryClassificationEvaluator\n",
    "\n",
    "# Load training data\n",
    "training = spark.read.format(\"libsvm\").load(\"file:///E://download/sample_libsvm_data.txt\")\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(training)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))\n",
    "\n",
    "# We can also use the multinomial family for binary classification\n",
    "mlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n",
    "\n",
    "# Fit the model\n",
    "mlrModel = mlr.fit(training)\n",
    "\n",
    "\n",
    "# Print the coefficients and intercepts for logistic regression with multinomial family\n",
    "print(\"Multinomial coefficients: \" + str(mlrModel.coefficientMatrix))\n",
    "print(\"Multinomial intercepts: \" + str(mlrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, features: vector]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator,BinaryClassificationEvaluator\n",
    "#regEvaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\",metricName=\"\")\n",
    "#regEvaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\",metricName=\"\")\n",
    "#preds = mlrModel.transform(training) # 多分类模型\n",
    "#preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds.select(\"label\",\"rawPrediction\",\"probability\",\"prediction\").collect()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回归评估\n",
    "#regEvaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\",metricName=\"rmse\") # rmse方式评估\n",
    "binEvaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\",metricName=\"areaUnderROC\")\n",
    "#roc = binEvaluator.evaluate(preds) # 评估预测\n",
    "#print(roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder,CrossValidator,TrainValidationSplit\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(mlr.elasticNetParam,[0.1, 0.5, 0.7, 0.9]).build()\n",
    "tvs = TrainValidationSplit(estimator=mlr,estimatorParamMaps=paramGrid,evaluator=binEvaluator,trainRatio=0.7)\n",
    "\n",
    "tvs_model = tvs.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 0.9583333333333333]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs_model.bestModel.elasticNetParam\n",
    "tvs_model.bestModel.extractParamMap()\n",
    "tvs_model.bestModel.getParam(\"elasticNetParam\")\n",
    "tvs_model.evaluator\n",
    "tvs_model.validationMetrics # 校验每个参数的评估得分\n",
    "#zip(tvs_model.avgMetrics, paramGrid) # CrossValidator中avgMetrics评估metric和参数网格一一对应\n",
    "#tvs_model.bestModel.stages[1].extractParamMap # 找到最佳模型下的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = tvs_model.transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=0.0, rawPrediction=DenseVector([1.5337, -1.5337]), probability=DenseVector([0.9555, 0.0445]), prediction=0.0),\n",
       " Row(label=1.0, rawPrediction=DenseVector([-1.5251, 1.5251]), probability=DenseVector([0.0452, 0.9548]), prediction=1.0),\n",
       " Row(label=1.0, rawPrediction=DenseVector([-1.8529, 1.8529]), probability=DenseVector([0.024, 0.976]), prediction=1.0),\n",
       " Row(label=1.0, rawPrediction=DenseVector([-1.4583, 1.4583]), probability=DenseVector([0.0513, 0.9487]), prediction=1.0),\n",
       " Row(label=1.0, rawPrediction=DenseVector([-1.5931, 1.5931]), probability=DenseVector([0.0397, 0.9603]), prediction=1.0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.select(\"label\",\"rawPrediction\",\"probability\",\"prediction\").collect()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
