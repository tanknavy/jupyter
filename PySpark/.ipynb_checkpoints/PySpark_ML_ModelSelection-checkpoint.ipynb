{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "管道+模型选择\n",
    "'''\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"PySpark_DataFrame\").master(\"local[2]\").\\\n",
    "config(\"spark.sql.warehouse.dir\",\"file:///E:/input/spark/warehouse\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline # 管道\n",
    "from pyspark.ml.classification import LogisticRegression # 逻辑回归算法\n",
    "from pyspark.ml.feature import HashingTF,Tokenizer # 特征转换\n",
    "from pyspark.ml.tuning import ParamGridBuilder,CrossValidator,TrainValidationSplit # 参数和模型选择\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator # 二分类评估\n",
    "\n",
    "train = spark.createDataFrame([\n",
    "    (0, \"a b c d e spark\", 1.0),\n",
    "    (1, \"b d\", 0.0),\n",
    "    (2, \"spark f g h\", 1.0),\n",
    "    (3, \"hadoop mapreduce\", 0.0),\n",
    "    (4, \"b spark who\", 1.0),\n",
    "    (5, \"g d a y\", 0.0),\n",
    "    (6, \"spark fly\", 1.0),\n",
    "    (7, \"was mapreduce\", 0.0),\n",
    "    (8, \"e spark program\", 1.0),\n",
    "    (9, \"a e c l\", 0.0),\n",
    "    (10, \"spark compile\", 1.0),\n",
    "    (11, \"hadoop software\", 0.0)\n",
    "], [\"id\", \"text\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\",outputCol='words') # 分词\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\") # tf-idf词频\n",
    "lr = LogisticRegression(maxIter=20,regParam=0.01)\n",
    "pipeline = Pipeline(stages=[tokenizer,hashtingTF,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#参数网格\n",
    "paramGrid = ParamGridBuilder().\\\n",
    "    addGrid(hashingTF.numFeatures,[10,100,1000]).\\\n",
    "    addGrid(lr.regParam,[0.1,0.01]).build()\n",
    "\n",
    "# 2折交叉校验选择数据(估计器，估计网格参数，评估器，n折)\n",
    "crossval = CrossValidator(estimator=pipeline,estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),numFolds=2)\n",
    "\n",
    "cvModel = crossval.fit(train) # 训练数据，最终使用最佳参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, {Param(parent='HashingTF_497594a8bbb4b02a1826', name='numFeatures', doc='number of features.'): 10, Param(parent='LogisticRegression_4aa7b7a7857c802d97d7', name='regParam', doc='regularization parameter (>= 0).'): 0.1}), (0.8333333333333334, {Param(parent='HashingTF_497594a8bbb4b02a1826', name='numFeatures', doc='number of features.'): 10, Param(parent='LogisticRegression_4aa7b7a7857c802d97d7', name='regParam', doc='regularization parameter (>= 0).'): 0.01}), (1.0, {Param(parent='HashingTF_497594a8bbb4b02a1826', name='numFeatures', doc='number of features.'): 100, Param(parent='LogisticRegression_4aa7b7a7857c802d97d7', name='regParam', doc='regularization parameter (>= 0).'): 0.1}), (0.8333333333333334, {Param(parent='HashingTF_497594a8bbb4b02a1826', name='numFeatures', doc='number of features.'): 100, Param(parent='LogisticRegression_4aa7b7a7857c802d97d7', name='regParam', doc='regularization parameter (>= 0).'): 0.01}), (1.0, {Param(parent='HashingTF_497594a8bbb4b02a1826', name='numFeatures', doc='number of features.'): 1000, Param(parent='LogisticRegression_4aa7b7a7857c802d97d7', name='regParam', doc='regularization parameter (>= 0).'): 0.1}), (0.8333333333333334, {Param(parent='HashingTF_497594a8bbb4b02a1826', name='numFeatures', doc='number of features.'): 1000, Param(parent='LogisticRegression_4aa7b7a7857c802d97d7', name='regParam', doc='regularization parameter (>= 0).'): 0.01})]\n"
     ]
    }
   ],
   "source": [
    "#dir(cvModel)\n",
    "pp = zip(cvModel.avgMetrics, paramGrid) # 评估metric和参数网格一一对应\n",
    "cvModel.params\n",
    "tf = cvModel.bestModel.stages[1].extractParamMap # 找到最佳模型下的\n",
    "tf()\n",
    "print(list(pp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spark.createDataFrame([\n",
    "    (4, \"spark i j k\"),\n",
    "    (5, \"l m n\"),\n",
    "    (6, \"mapreduce spark\"),\n",
    "    (7, \"apache hadoop\")\n",
    "], [\"id\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(id=4, text='spark i j k', probability=DenseVector([0.2665, 0.7335]), prediction=1.0)\n",
      "Row(id=5, text='l m n', probability=DenseVector([0.9204, 0.0796]), prediction=0.0)\n",
      "Row(id=6, text='mapreduce spark', probability=DenseVector([0.4438, 0.5562]), prediction=1.0)\n",
      "Row(id=7, text='apache hadoop', probability=DenseVector([0.8587, 0.1413]), prediction=0.0)\n"
     ]
    }
   ],
   "source": [
    "prediction = cvModel.transform(test)\n",
    "selected = prediction.select(\"id\", \"text\", \"probability\", \"prediction\")\n",
    "for row in selected.collect():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-validation split # 为了超参调节\n",
    "from pyspark.ml.tuning import ParamGridBuilder,TrainValidationSplit\n",
    "\n",
    "# dataframe实现分为训练集和测试集\n",
    "data = spark.read.format(\"libsvm\")\\\n",
    "    .load(\"data/mllib/sample_linear_regression_data.txt\")\n",
    "train, test = data.randomSplit([0.9, 0.1], seed=12345)\n",
    "\n",
    "# 同上CrossValidator, 使用一个校验\n",
    "tvs = TrainValidationSplit(estimator=lr,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=RegressionEvaluator(),\n",
    "                           # 80% of the data will be used for training, 20% for validation.\n",
    "                           trainRatio=0.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
