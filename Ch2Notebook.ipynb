{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapater 2 Code - Python 3 version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### abaloneCorrHeat.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 504: Proxy Timeout ( The connection timed out.  )",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5df92c6e2246>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m               \"learning-databases/abalone/abalone.data\")\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#read abalone data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mabalone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_url\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"V\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m abalone.columns = ['Sex', 'Length', 'Diameter', 'Height',\n\u001b[0;32m     12\u001b[0m                    \u001b[1;34m'Whole weight'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Shucked weight'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ac32\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ac32\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[0mcompression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_infer_compression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m     filepath_or_buffer, _, compression, should_close = get_filepath_or_buffer(\n\u001b[1;32m--> 424\u001b[1;33m         filepath_or_buffer, encoding, compression)\n\u001b[0m\u001b[0;32m    425\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'compression'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ac32\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_urlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Content-Encoding'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'gzip'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ac32\\AppData\\Local\\Continuum\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ac32\\AppData\\Local\\Continuum\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    470\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 472\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ac32\\AppData\\Local\\Continuum\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 582\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ac32\\AppData\\Local\\Continuum\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[1;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ac32\\AppData\\Local\\Continuum\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ac32\\AppData\\Local\\Continuum\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 504: Proxy Timeout ( The connection timed out.  )"
     ]
    }
   ],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plot\n",
    "%matplotlib inline\n",
    "\n",
    "target_url = (\"http://archive.ics.uci.edu/ml/machine-\"\n",
    "              \"learning-databases/abalone/abalone.data\")\n",
    "#read abalone data\n",
    "abalone = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "abalone.columns = ['Sex', 'Length', 'Diameter', 'Height',\n",
    "                   'Whole weight', 'Shucked weight',\n",
    "                   'Viscera weight', 'Shell weight', 'Rings']\n",
    "\n",
    "#calculate correlation matrix\n",
    "corMat = DataFrame(abalone.iloc[:,1:9].corr())\n",
    "#print correlation matrix\n",
    "print(corMat)\n",
    "\n",
    "#visualize correlations using heatmap\n",
    "plot.pcolor(corMat)\n",
    "plot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### abaloneParallelPlot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plot\n",
    "from math import exp\n",
    "target_url = (\"http://archive.ics.uci.edu/ml/machine-\"\n",
    "              \"learning-databases/abalone/abalone.data\")\n",
    "#read abalone data\n",
    "abalone = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "abalone.columns = ['Sex', 'Length', 'Diameter', 'Height',\n",
    "                   'Whole Wt', 'Shucked Wt',\n",
    "                   'Viscera Wt', 'Shell Wt', 'Rings']\n",
    "#get summary to use for scaling\n",
    "summary = abalone.describe()\n",
    "minRings = summary.iloc[3,7]\n",
    "maxRings = summary.iloc[7,7]\n",
    "nrows = len(abalone.index)\n",
    "\n",
    "for i in range(nrows):\n",
    "    #plot rows of data as if they were series data\n",
    "    dataRow = abalone.iloc[i,1:8]\n",
    "    labelColor = (abalone.iloc[i,8] - minRings) / (maxRings - minRings)\n",
    "    dataRow.plot(color=plot.cm.RdYlBu(labelColor), alpha=0.5)\n",
    "\n",
    "plot.xlabel(\"Attribute Index\")\n",
    "plot.ylabel((\"Attribute Values\"))\n",
    "plot.show()\n",
    "\n",
    "#renormalize using mean and standard variation, then compress\n",
    "# with logit function\n",
    "\n",
    "meanRings = summary.iloc[1,7]\n",
    "sdRings = summary.iloc[2,7]\n",
    "\n",
    "for i in range(nrows):\n",
    "    #plot rows of data as if they were series data\n",
    "    dataRow = abalone.iloc[i,1:8]\n",
    "    normTarget = (abalone.iloc[i,8] - meanRings)/sdRings\n",
    "    labelColor = 1.0/(1.0 + exp(-normTarget))\n",
    "    dataRow.plot(color=plot.cm.RdYlBu(labelColor), alpha=0.5)\n",
    "\n",
    "plot.xlabel(\"Attribute Index\")\n",
    "plot.ylabel((\"Attribute Values\"))\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### abaloneSummary.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "target_url = (\"http://archive.ics.uci.edu/ml/machine-\"\n",
    "              \"learning-databases/abalone/abalone.data\")\n",
    "#read abalone data\n",
    "abalone = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "abalone.columns = ['Sex', 'Length', 'Diameter', 'Height', 'Whole weight',\n",
    "                   'Shucked weight', 'Viscera weight', 'Shell weight',\n",
    "                   'Rings']\n",
    "\n",
    "\n",
    "print(abalone.head())\n",
    "print(abalone.tail())\n",
    "\n",
    "#print summary of data frame\n",
    "summary = abalone.describe()\n",
    "print(summary)\n",
    "\n",
    "#box plot the real-valued attributes\n",
    "#convert to array for plot routine\n",
    "array = abalone.iloc[:,1:9].values\n",
    "boxplot(array)\n",
    "plot.xlabel(\"Attribute Index\")\n",
    "plot.ylabel((\"Quartile Ranges\"))\n",
    "show()\n",
    "\n",
    "#the last column (rings) is out of scale with the rest\n",
    "# - remove and replot\n",
    "array2 = abalone.iloc[:,1:8].values\n",
    "boxplot(array2)\n",
    "plot.xlabel(\"Attribute Index\")\n",
    "plot.ylabel((\"Quartile Ranges\"))\n",
    "show()\n",
    "\n",
    "#removing is okay but renormalizing the variables generalizes better.\n",
    "#renormalize columns to zero mean and unit standard deviation\n",
    "#this is a common normalization and desirable for other operations\n",
    "# (like k-means clustering or k-nearest neighbors\n",
    "abaloneNormalized = abalone.iloc[:,1:9]\n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "    mean = summary.iloc[1, i]\n",
    "    sd = summary.iloc[2, i]\n",
    "    abaloneNormalized.iloc[:,i:(i + 1)] = (\n",
    "                    abaloneNormalized.iloc[:,i:(i + 1)] - mean) / sd\n",
    "\n",
    "array3 = abaloneNormalized.values\n",
    "boxplot(array3)\n",
    "plot.xlabel(\"Attribute Index\")\n",
    "plot.ylabel((\"Quartile Ranges - Normalized \"))\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classifierExamplePlot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "from random import uniform\n",
    "\n",
    "#Simulate easy to classify examples\n",
    "\n",
    "x = []\n",
    "target = []\n",
    "for i in range(200):\n",
    "    #make up easy data points\n",
    "    x.append(0.2 + uniform(-0.1, 0.1))\n",
    "    target.append(1.0 + uniform(-0.1, 0.1))\n",
    "    x.append(0.8 + uniform(-0.1, 0.1))\n",
    "    target.append(0.0 + uniform(-0.1, 0.1))\n",
    "\n",
    "\n",
    "plot.scatter(x, target, alpha=0.5)\n",
    "\n",
    "plot.xlabel(\"Attribute Value\")\n",
    "plot.ylabel(\"Target Value\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### corrCalc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from math import sqrt\n",
    "import sys\n",
    "target_url = (\"https://archive.ics.uci.edu/ml/machine-learning-\"\n",
    "\"databases/undocumented/connectionist-bench/sonar/sonar.all-data\")\n",
    "\n",
    "#read rocks versus mines data into pandas data frame\n",
    "rocksVMines = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "\n",
    "#calculate correlations between real-valued attributes\n",
    "dataRow2 = rocksVMines.iloc[1,0:60]\n",
    "dataRow3 = rocksVMines.iloc[2,0:60]\n",
    "dataRow21 = rocksVMines.iloc[20,0:60]\n",
    "\n",
    "mean2 = 0.0; mean3 = 0.0; mean21 = 0.0\n",
    "numElt = len(dataRow2)\n",
    "for i in range(numElt):\n",
    "    mean2 += dataRow2[i]/numElt\n",
    "    mean3 += dataRow3[i]/numElt\n",
    "    mean21 += dataRow21[i]/numElt\n",
    "\n",
    "var2 = 0.0; var3 = 0.0; var21 = 0.0\n",
    "for i in range(numElt):\n",
    "    var2 += (dataRow2[i] - mean2) * (dataRow2[i] - mean2)/numElt\n",
    "    var3 += (dataRow3[i] - mean3) * (dataRow3[i] - mean3)/numElt\n",
    "    var21 += (dataRow21[i] - mean21) * (dataRow21[i] - mean21)/numElt\n",
    "\n",
    "corr23 = 0.0; corr221 = 0.0\n",
    "for i in range(numElt):\n",
    "    corr23 += (dataRow2[i] - mean2) * \\\n",
    "              (dataRow3[i] - mean3) / (sqrt(var2*var3) * numElt)\n",
    "    corr221 += (dataRow2[i] - mean2) * \\\n",
    "               (dataRow21[i] - mean21) / (sqrt(var2*var21) * numElt)\n",
    "\n",
    "sys.stdout.write(\"Correlation between attribute 2 and 3 \\n\")\n",
    "print(corr23)\n",
    "sys.stdout.write(\" \\n\")\n",
    "\n",
    "sys.stdout.write(\"Correlation between attribute 2 and 21 \\n\")\n",
    "print(corr221)\n",
    "sys.stdout.write(\" \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### corrPlot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plot\n",
    "target_url = (\"https://archive.ics.uci.edu/ml/machine-learning-\"\n",
    "\"databases/undocumented/connectionist-bench/sonar/sonar.all-data\")\n",
    "\n",
    "#read rocks versus mines data into pandas data frame\n",
    "rocksVMines = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "\n",
    "#calculate correlations between real-valued attributes\n",
    "dataRow2 = rocksVMines.iloc[1,0:60]\n",
    "dataRow3 = rocksVMines.iloc[2,0:60]\n",
    "\n",
    "plot.scatter(dataRow2, dataRow3)\n",
    "\n",
    "\n",
    "plot.xlabel(\"2nd Attribute\")\n",
    "plot.ylabel((\"3rd Attribute\"))\n",
    "plot.show()\n",
    "\n",
    "dataRow21 = rocksVMines.iloc[20,0:60]\n",
    "\n",
    "plot.scatter(dataRow2, dataRow21)\n",
    "\n",
    "\n",
    "plot.xlabel(\"2nd Attribute\")\n",
    "plot.ylabel((\"21st Attribute\"))\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### glassCorrHeatMap.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plot\n",
    "from math import exp\n",
    "\n",
    "target_url = (\"https://archive.ics.uci.edu/ml/machine-\"\n",
    "              \"learning-databases/glass/glass.data\")\n",
    "glass = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "glass.columns = ['Id', 'RI', 'Na', 'Mg', 'Al', 'Si',\n",
    "                 'K', 'Ca', 'Ba', 'Fe', 'Type']\n",
    "ncols = len(glass.columns)\n",
    "\n",
    "#calculate correlation matrix\n",
    "corMat = DataFrame(glass.iloc[:, 1:(ncols - 1)].corr())\n",
    "\n",
    "#visualize correlations using heatmap\n",
    "plot.pcolor(corMat)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### glassParallelPlot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "target_url = (\"https://archive.ics.uci.edu/ml/machine-\"\n",
    "              \"learning-databases/glass/glass.data\")\n",
    "glass = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "glass.columns = ['Id', 'RI', 'Na', 'Mg', 'Al', 'Si',\n",
    "                 'K', 'Ca', 'Ba', 'Fe', 'Type']\n",
    "\n",
    "\n",
    "glassNormalized = glass\n",
    "ncols = len(glassNormalized.columns)\n",
    "nrows = len(glassNormalized.index)\n",
    "summary = glassNormalized.describe()\n",
    "nDataCol = ncols - 1\n",
    "\n",
    "#normalize except for labels\n",
    "for i in range(ncols - 1):\n",
    "    mean = summary.iloc[1, i]\n",
    "    sd = summary.iloc[2, i]\n",
    "    glassNormalized.iloc[:,i:(i + 1)] = \\\n",
    "        (glassNormalized.iloc[:,i:(i + 1)] - mean) / sd\n",
    "\n",
    "#Plot Parallel Coordinate Graph with normalized values\n",
    "for i in range(nrows):\n",
    "    #plot rows of data as if they were series data\n",
    "    dataRow = glassNormalized.iloc[i,1:nDataCol]\n",
    "    labelColor = glassNormalized.iloc[i,nDataCol]/7.0\n",
    "    dataRow.plot(color=plot.cm.RdYlBu(labelColor), alpha=0.5)\n",
    "\n",
    "plot.xlabel(\"Attribute Index\")\n",
    "plot.ylabel((\"Attribute Values\"))\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### glassSummary.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "target_url = (\"https://archive.ics.uci.edu/ml/machine-\"\n",
    "              \"learning-databases/glass/glass.data\")\n",
    "\n",
    "glass = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "glass.columns = ['Id', 'RI', 'Na', 'Mg', 'Al', 'Si',\n",
    "                 'K', 'Ca', 'Ba', 'Fe', 'Type']\n",
    "\n",
    "print(glass.head())\n",
    "\n",
    "#generate statistical summaries\n",
    "summary = glass.describe()\n",
    "print(summary)\n",
    "ncol1 = len(glass.columns)\n",
    "\n",
    "glassNormalized = glass.iloc[:, 1:ncol1]\n",
    "ncol2 = len(glassNormalized.columns)\n",
    "summary2 = glassNormalized.describe()\n",
    "\n",
    "for i in range(ncol2):\n",
    "    mean = summary2.iloc[1, i]\n",
    "    sd = summary2.iloc[2, i]\n",
    "    glassNormalized.iloc[:,i:(i + 1)] = \\\n",
    "        (glassNormalized.iloc[:,i:(i + 1)] - mean) / sd\n",
    "\n",
    "array = glassNormalized.values\n",
    "boxplot(array)\n",
    "plot.xlabel(\"Attribute Index\")\n",
    "plot.ylabel((\"Quartile Ranges - Normalized \"))\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linePlots.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plot\n",
    "target_url = (\"https://archive.ics.uci.edu/ml/machine-learning-\"\n",
    "\"databases/undocumented/connectionist-bench/sonar/sonar.all-data\")\n",
    "\n",
    "#read rocks versus mines data into pandas data frame\n",
    "rocksVMines = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "\n",
    "for i in range(208):\n",
    "    #assign color based on color based on \"M\" or \"R\" labels\n",
    "    if rocksVMines.iat[i,60] == \"M\":\n",
    "        pcolor = \"red\"\n",
    "    else:\n",
    "        pcolor = \"blue\"\n",
    "\n",
    "    #plot rows of data as if they were series data\n",
    "    dataRow = rocksVMines.iloc[i,0:60]\n",
    "    dataRow.plot(color=pcolor, alpha=0.5)\n",
    "\n",
    "plot.xlabel(\"Attribute Index\")\n",
    "plot.ylabel((\"Attribute Values\"))\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logitCurve.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "import matplotlib.pyplot as plot\n",
    "from math import exp\n",
    "\n",
    "x = [i*0.1 for i in range(-90, 91)]\n",
    "y = [1.0/(1.0 + exp(-i*0.1)) for i in range(-90, 91)]\n",
    "plot.scatter(x, y)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandasReadSummarize.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plot\n",
    "target_url = (\"https://archive.ics.uci.edu/ml/machine-learning-\"\n",
    "\"databases/undocumented/connectionist-bench/sonar/sonar.all-data\")\n",
    "\n",
    "#read rocks versus mines data into pandas data frame\n",
    "rocksVMines = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "\n",
    "#print head and tail of data frame\n",
    "print(rocksVMines.head())\n",
    "print(rocksVMines.tail())\n",
    "\n",
    "#print summary of data frame\n",
    "summary = rocksVMines.describe()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### qqplotAttribute.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'ubuntu'\n",
    "import numpy as np\n",
    "import pylab\n",
    "import scipy.stats as stats\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "import sys\n",
    "\n",
    "target_url = (\"https://archive.ics.uci.edu/ml/machine-learning-\"\n",
    "\"databases/undocumented/connectionist-bench/sonar/sonar.all-data\")\n",
    "\n",
    "data = urllib.request.urlopen(target_url)\n",
    "\n",
    "#arrange data into list for labels and list of lists for attributes\n",
    "xList = []\n",
    "labels = []\n",
    "\n",
    "for line in data:\n",
    "    #split on comma\n",
    "    row = line.strip().decode().split(\",\")\n",
    "    xList.append(row)\n",
    "nrow = len(xList)\n",
    "ncol = len(xList[1])\n",
    "\n",
    "type = [0]*3\n",
    "colCounts = []\n",
    "\n",
    "#generate summary statistics for column 3 (e.g.)\n",
    "col = 3\n",
    "colData = []\n",
    "for row in xList:\n",
    "    colData.append(float(row[col]))\n",
    "\n",
    "\n",
    "stats.probplot(colData, dist=\"norm\", plot=pylab)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### readPandas.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plot\n",
    "target_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\"\n",
    "\n",
    "#read rocks versus mines data into pandas data frame\n",
    "rocksVMines = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "\n",
    "#calculate correlations between real-valued attributes\n",
    "\n",
    "corMat = DataFrame(rocksVMines.corr())\n",
    "\n",
    "#visualize correlations using heatmap\n",
    "plot.pcolor(corMat)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rockVmineContents.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "import sys\n",
    "\n",
    "#read data from uci data repository\n",
    "target_url = (\"https://archive.ics.uci.edu/ml/machine-learning-\"\n",
    "\"databases/undocumented/connectionist-bench/sonar/sonar.all-data\")\n",
    "\n",
    "data = urllib.request.urlopen(target_url)\n",
    "\n",
    "#arrange data into list for labels and list of lists for attributes\n",
    "xList = []\n",
    "labels = []\n",
    "\n",
    "for line in data:\n",
    "    #split on comma\n",
    "    row = line.strip().decode().split(\",\")\n",
    "    xList.append(row)\n",
    "nrow = len(xList)\n",
    "ncol = len(xList[1])\n",
    "\n",
    "type = [0]*3\n",
    "colCounts = []\n",
    "\n",
    "for col in range(ncol):\n",
    "    for row in xList:\n",
    "        try:\n",
    "            a = float(row[col])\n",
    "            if isinstance(a, float):\n",
    "                type[0] += 1\n",
    "        except ValueError:\n",
    "            if len(row[col]) > 0:\n",
    "                type[1] += 1\n",
    "            else:\n",
    "                type[2] += 1\n",
    "\n",
    "    colCounts.append(type)\n",
    "    type = [0]*3\n",
    "\n",
    "sys.stdout.write(\"Col#\" + '\\t' + \"Number\" + '\\t' +\n",
    "                 \"Strings\" + '\\t ' + \"Other\\n\")\n",
    "iCol = 0\n",
    "for types in colCounts:\n",
    "    sys.stdout.write(str(iCol) + '\\t\\t' + str(types[0]) + '\\t\\t' +\n",
    "                     str(types[1]) + '\\t\\t' + str(types[2]) + \"\\n\")\n",
    "    iCol += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rockVmineSummaries.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "import sys\n",
    "\n",
    "#read data from uci data repository\n",
    "target_url = (\"https://archive.ics.uci.edu/ml/machine-learning-\"\n",
    "\"databases/undocumented/connectionist-bench/sonar/sonar.all-data\")\n",
    "\n",
    "data = urllib.request.urlopen(target_url)\n",
    "\n",
    "#arrange data into list for labels and list of lists for attributes\n",
    "xList = []\n",
    "labels = []\n",
    "for line in data:\n",
    "    #split on comma\n",
    "    row = line.strip().decode().split(\",\")\n",
    "    xList.append(row)\n",
    "\n",
    "sys.stdout.write(\"Number of Rows of Data = \" + str(len(xList)) + '\\n')\n",
    "sys.stdout.write(\"Number of Columns of Data = \" + str(len(xList[1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rVMSummaryStats.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "#read data from uci data repository\n",
    "target_url = (\"https://archive.ics.uci.edu/ml/machine-learning-\"\n",
    "\"databases/undocumented/connectionist-bench/sonar/sonar.all-data\")\n",
    "\n",
    "data = urllib.request.urlopen(target_url)\n",
    "\n",
    "#arrange data into list for labels and list of lists for attributes\n",
    "xList = []\n",
    "labels = []\n",
    "\n",
    "for line in data:\n",
    "    #split on comma\n",
    "    row = line.strip().decode().split(\",\")\n",
    "    xList.append(row)\n",
    "nrow = len(xList)\n",
    "ncol = len(xList[1])\n",
    "\n",
    "type = [0]*3\n",
    "colCounts = []\n",
    "\n",
    "#generate summary statistics for column 3 (e.g.)\n",
    "col = 3\n",
    "colData = []\n",
    "for row in xList:\n",
    "    colData.append(float(row[col]))\n",
    "\n",
    "colArray = np.array(colData)\n",
    "colMean = np.mean(colArray)\n",
    "colsd = np.std(colArray)\n",
    "sys.stdout.write(\"Mean = \" + '\\t' + str(colMean) + '\\t\\t' +\n",
    "            \"Standard Deviation = \" + '\\t ' + str(colsd) + \"\\n\")\n",
    "\n",
    "\n",
    "#calculate quantile boundaries\n",
    "ntiles = 4\n",
    "\n",
    "percentBdry = []\n",
    "\n",
    "for i in range(ntiles+1):\n",
    "    percentBdry.append(np.percentile(colArray, i*(100)/ntiles))\n",
    "\n",
    "sys.stdout.write(\"\\nBoundaries for 4 Equal Percentiles \\n\")\n",
    "print(percentBdry)\n",
    "sys.stdout.write(\" \\n\")\n",
    "\n",
    "\n",
    "#run again with 10 equal intervals\n",
    "ntiles = 10\n",
    "\n",
    "percentBdry = []\n",
    "\n",
    "for i in range(ntiles+1):\n",
    "    percentBdry.append(np.percentile(colArray, i*(100)/ntiles))\n",
    "\n",
    "sys.stdout.write(\"Boundaries for 10 Equal Percentiles \\n\")\n",
    "print(percentBdry)\n",
    "sys.stdout.write(\" \\n\")\n",
    "\n",
    "\n",
    "#The last column contains categorical variables\n",
    "\n",
    "col = 60\n",
    "colData = []\n",
    "for row in xList:\n",
    "    colData.append(row[col])\n",
    "\n",
    "unique = set(colData)\n",
    "sys.stdout.write(\"Unique Label Values \\n\")\n",
    "print(unique)\n",
    "\n",
    "#count up the number of elements having each value\n",
    "\n",
    "catDict = dict(zip(list(unique),range(len(unique))))\n",
    "\n",
    "catCount = [0]*2\n",
    "\n",
    "for elt in colData:\n",
    "    catCount[catDict[elt]] += 1\n",
    "\n",
    "sys.stdout.write(\"\\nCounts for Each Value of Categorical Label \\n\")\n",
    "print(list(unique))\n",
    "print(catCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sampleCorrHeatMap.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plot\n",
    "target_url = (\"https://archive.ics.uci.edu/ml/machine-learning-\"\n",
    "\"databases/undocumented/connectionist-bench/sonar/sonar.all-data\")\n",
    "\n",
    "#read rocks versus mines data into pandas data frame\n",
    "rocksVMines = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "\n",
    "#calculate correlations between real-valued attributes\n",
    "\n",
    "corMat = DataFrame(rocksVMines.corr())\n",
    "\n",
    "#visualize correlations using heatmap\n",
    "plot.pcolor(corMat)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### targetCorr.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plot\n",
    "from random import uniform\n",
    "target_url = (\"https://archive.ics.uci.edu/ml/machine-learning-\"\n",
    "\"databases/undocumented/connectionist-bench/sonar/sonar.all-data\")\n",
    "\n",
    "#read rocks versus mines data into pandas data frame\n",
    "rocksVMines = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "\n",
    "#change the targets to numeric values\n",
    "target = []\n",
    "for i in range(208):\n",
    "    #assign 0 or 1 target value based on \"M\" or \"R\" labels\n",
    "    if rocksVMines.iat[i,60] == \"M\":\n",
    "        target.append(1.0)\n",
    "    else:\n",
    "        target.append(0.0)\n",
    "\n",
    "    #plot rows of data as if they were series data\n",
    "dataRow = rocksVMines.iloc[0:208,35]\n",
    "plot.scatter(dataRow, target)\n",
    "\n",
    "plot.xlabel(\"Attribute Value\")\n",
    "plot.ylabel(\"Target Value\")\n",
    "plot.show()\n",
    "\n",
    "#\n",
    "#To improve the visualization, this version dithers the points a little\n",
    "# and makes them somewhat transparent\n",
    "target = []\n",
    "for i in range(208):\n",
    "    #assign 0 or 1 target value based on \"M\" or \"R\" labels\n",
    "    # and add some dither\n",
    "    if rocksVMines.iat[i,60] == \"M\":\n",
    "        target.append(1.0 + uniform(-0.1, 0.1))\n",
    "    else:\n",
    "        target.append(0.0 + uniform(-0.1, 0.1))\n",
    "\n",
    "    #plot rows of data as if they were series data\n",
    "dataRow = rocksVMines.iloc[0:208,35]\n",
    "plot.scatter(dataRow, target, alpha=0.5, s=120)\n",
    "\n",
    "plot.xlabel(\"Attribute Value\")\n",
    "plot.ylabel(\"Target Value\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wineCorrHeatMap.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plot\n",
    "from math import exp\n",
    "\n",
    "target_url = (\"http://archive.ics.uci.edu/ml/machine-\"\n",
    "              \"learning-databases/wine-quality/winequality-red.csv\")\n",
    "wine = pd.read_csv(target_url,header=0, sep=\";\")\n",
    "wineCols = len(wine.columns)\n",
    "\n",
    "#calculate correlation matrix\n",
    "corMat = DataFrame(wine.corr())\n",
    "\n",
    "#visualize correlations using heatmap\n",
    "plot.pcolor(corMat)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wineParallelPlot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plot\n",
    "from math import exp\n",
    "\n",
    "target_url = (\"http://archive.ics.uci.edu/ml/machine-\"\n",
    " \"learning-databases/wine-quality/winequality-red.csv\")\n",
    "\n",
    "wine = pd.read_csv(target_url,header=0, sep=\";\")\n",
    "\n",
    "#print column names in order to have the full versions\n",
    "print(wine.columns)\n",
    "\n",
    "#change column names to shorter ones to fit graph\n",
    "wine.columns = ['fixAcid', 'volAcid', 'citAcid',\n",
    "    'resSugr', 'chlor', 'frSO2', 'totSO2',\n",
    "    'dens', 'pH', 'sulpha', 'alcohol', 'quality']\n",
    "\n",
    "#generate statistical summaries\n",
    "summary = wine.describe()\n",
    "nrows = len(wine.index)\n",
    "tasteCol = len(summary.columns)\n",
    "meanTaste = summary.iloc[1,tasteCol - 1]\n",
    "sdTaste = summary.iloc[2,tasteCol - 1]\n",
    "nDataCol = len(wine.columns) -1\n",
    "\n",
    "for i in range(nrows):\n",
    "    #plot rows of data as if they were series data\n",
    "    dataRow = wine.iloc[i,1:nDataCol]\n",
    "    normTarget = (wine.iloc[i,nDataCol] - meanTaste)/sdTaste\n",
    "    labelColor = 1.0/(1.0 + exp(-normTarget))\n",
    "    dataRow.plot(color=plot.cm.RdYlBu(labelColor), alpha=0.5)\n",
    "\n",
    "plot.xlabel(\"Attribute Index\")\n",
    "plot.ylabel((\"Attribute Values\"))\n",
    "plot.show()\n",
    "\n",
    "wineNormalized = wine\n",
    "ncols = len(wineNormalized.columns)\n",
    "\n",
    "for i in range(ncols):\n",
    "    mean = summary.iloc[1, i]\n",
    "    sd = summary.iloc[2, i]\n",
    "    wineNormalized.iloc[:,i:(i + 1)] = \\\n",
    "        (wineNormalized.iloc[:,i:(i + 1)] - mean) / sd\n",
    "\n",
    "#Try again with normalized values\n",
    "for i in range(nrows):\n",
    "    #plot rows of data as if they were series data\n",
    "    dataRow = wineNormalized.iloc[i,1:nDataCol]\n",
    "    normTarget = wineNormalized.iloc[i,nDataCol]\n",
    "    labelColor = 1.0/(1.0 + exp(-normTarget))\n",
    "    dataRow.plot(color=plot.cm.RdYlBu(labelColor), alpha=0.5)\n",
    "\n",
    "plot.xlabel(\"Attribute Index\")\n",
    "plot.ylabel((\"Attribute Values\"))\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wineSummary.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'mike_bowles'\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "target_url = (\"http://archive.ics.uci.edu/ml/machine-\"\n",
    " \"learning-databases/wine-quality/winequality-red.csv\")\n",
    "\n",
    "wine = pd.read_csv(target_url,header=0, sep=\";\")\n",
    "\n",
    "print(wine.head())\n",
    "\n",
    "#generate statistical summaries\n",
    "summary = wine.describe()\n",
    "print(summary)\n",
    "\n",
    "wineNormalized = wine\n",
    "ncols = len(wineNormalized.columns)\n",
    "\n",
    "for i in range(ncols):\n",
    "    mean = summary.iloc[1, i]\n",
    "    sd = summary.iloc[2, i]\n",
    "    wineNormalized.iloc[:,i:(i + 1)] = \\\n",
    "        (wineNormalized.iloc[:,i:(i + 1)] - mean) / sd\n",
    "\n",
    "array = wineNormalized.values\n",
    "boxplot(array)\n",
    "plot.xlabel(\"Attribute Index\")\n",
    "plot.ylabel((\"Quartile Ranges - Normalized \"))\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
